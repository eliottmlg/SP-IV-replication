{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "outputExpanded": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This file was succesfully tested on Julia 1.3.1\n",
    "# Generates results for the Short-Run decomposition in the Frequency Domain\n",
    "# replacing the GDP deflator based inflation measure by the CORE based (starts in 1957Q2).\n",
    "include(\"../toolboxes/toolbox.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "outputExpanded": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbseed = 1234567890 # Seed to be used in the Gibbs sampler\n",
    "alpha  = 68         # We want 68% confidence bands\n",
    "lags   = 2          # Number of lags in the VAR\n",
    "gibbs_ = true       # false: if false, uses results stored in the filegibbs file \n",
    "T0     = 1957.25    # Initial date of sample (1960Q1 -> 1960, 1960Q2-> 1960.25, 1960Q3-> 1960.50, 1960Q4-> 1960.75)\n",
    "T1     = 2017.75    # Final date of sample\n",
    "Ndraws = 50000      # Total number of draws in Gibbs sampling\n",
    "Nburn  = 49000      # Burn in iterations\n",
    "maxhor = 200        # Maximal horizon when testing for LR effects\n",
    "nrep   = 40         # Number of periods \n",
    "test   = 1          # Testing period for the IRF\n",
    "save_  = true       # set to true to save results in a matlab file\n",
    "\n",
    "#\n",
    "# Specifying the type of analysis\n",
    "#   \n",
    "#\n",
    "# In case of Frequency domain:\n",
    "# wmin -> lowest frequency to consider  : BC analysis, wmin=2π/32, LR analysis, wmin=1e-5\n",
    "# wmax -> highest frequency to consider : BC analysis, wmax=2π/6,  LR analysis, wmax=2π/80  \n",
    "wmin    = 2*π/32       \n",
    "wmax    = 2*π/6        \n",
    "\n",
    "Idv     = [5,6,8]    # index of Variable (in the estimated VAR) for which we maximize the variance contribution\n",
    "                       # Here: 1->Y, 2->I, 3->C, 4->h ... (see below list of variables in the VAR)\n",
    "                       # assume that instead of looking at Y in isolation, you want to maximize over Y and u at the same time\n",
    "                       # then Idv would look like Idv=[[1,5],2,3,4,5,6,7,8,9,10]\n",
    "ncase   = length(Idv)\n",
    "\n",
    "filegibbs=\"../results_var/core_var_1955_2017_fd_sr.mat\" # File containing Gibbs results (if already ran) \n",
    "fileres = \"../results_var/core_var_1955_2017_fd_sr.mat\" # Result file\n",
    "\n",
    "# Read and prepare data (stored in a matlab data file)\n",
    "#************************************\n",
    "# First read the data:\n",
    "# Column Variable\n",
    "# 1      Quarters\n",
    "# 2      Y   : log real GDP\n",
    "# 3      I   : log real Investment\n",
    "# 4      C   : log real Consumption\n",
    "# 5      h   : log total Hours\n",
    "# 6      u   : Unemployment Rate\n",
    "# 7      Wh/Y: log Labor Share\n",
    "# 8      FFR : Federal Funds Rate\n",
    "# 9      ΔP  : Inflation Rate\n",
    "# 10     Y/h : Labor productivity\n",
    "# 11     TFP : Total Factor Productivity\n",
    "#************************************\n",
    "data   = matread(\"../data/data_1955_2017.mat\")\n",
    "data   = data[\"X\"]\n",
    "time   = data[:,1]\n",
    "data   = data[T0.<=time.<=T1,2:11] \n",
    "\n",
    "\n",
    "# Replaces the GDP deflator based quarterly\n",
    "datinf = matread(\"../data/inflation_data.mat\")\n",
    "Tinf   = datinf[\"time\"]\n",
    "dcore  = datinf[\"inf_core\"][T0.<=Tinf.<=T1]\n",
    "data[:,8]=copy(dcore)\n",
    "\n",
    "# Y, I, C, h, u, Wh/Y, FFR, Inflation, Y/h, TFP                                 \n",
    "# 1  2  3  4  5  6     7    8          9    10 \n",
    "########################################################################################################\n",
    "#\n",
    "# Compute the posterior distribution of the VAR\n",
    "#\n",
    "########################################################################################################\n",
    "# Priors\n",
    "AR     = [] # used to build priors (if empty, all variables have a RW prior)\n",
    "priors = minnesota_priors(data,AR,lags) # builds the prior object\n",
    "resvar = varest(data,lags)              # estimates the VAR\n",
    "\n",
    "# Gibbs Sampling\n",
    "if gibbs_\n",
    "    gibbs = gibbs_var(resvar,priors,Ndraws,Nburn;seed=gbseed)\n",
    "    VOL   = gibbs.vol;\n",
    "    COEFS = gibbs.coefs;\n",
    "else\n",
    "    tmp   = matread(filegibbs)\n",
    "    VOL   = tmp[\"VOL\"]\n",
    "    COEFS = tmp[\"COEFS\"]    \n",
    "end\n",
    "\n",
    "# Build a selection matrix of variables \n",
    "# (useful for the state space representation of the VAR)\n",
    "# y i c h u sw R pi y/h TFP \n",
    "# 1 2 3 4 5 6  7 8  9   10\n",
    "nvar    = resvar.nvar\n",
    "Ident   = eye(nvar)\n",
    "MYtmp   = [eye(nvar) zeros(nvar,nvar*(lags-1))]\n",
    "MY      = MYtmp[1:10,:]\n",
    "ny      = size(MY,1)\n",
    "\n",
    "########################################################################################################\n",
    "#\n",
    "# Build IRFs, Variance decomposition and Forecast errors decomposition\n",
    "#\n",
    "########################################################################################################\n",
    "\n",
    "# Storage:\n",
    "# 1st index: case under consideration (contained in Idv)\n",
    "# 2nd index: draws \n",
    "# 3rd index: variable or variable*horizon (for IRFs and FEV)\n",
    "Qmat    = zeros(ncase,Ndraws-Nburn,nvar)        # Impulse vector\n",
    "IRFsr   = zeros(ncase,Ndraws-Nburn,ny*nrep)     # contains IRFs\n",
    "SVTsr   = zeros(ncase,Ndraws-Nburn,ny)          # Short unr contribution (6-32 quarters)\n",
    "SVTlr   = zeros(ncase,Ndraws-Nburn,ny)          # Long run contribution (80-inf quarters)\n",
    "VD      = zeros(ncase,Ndraws-Nburn,ny*maxhor)   # standard FEV\n",
    "\n",
    "p = Progress(Ndraws-Nburn,1,\"Progress ... \",80)\n",
    "for i in 1:Ndraws-Nburn\n",
    "    update!(p,i)\n",
    "    # 1) Build the state space representation of the VAR for draw i\n",
    "    tmp   = VOL[i,:];\n",
    "    S     = Array(chol(Hermitian(reshape(tmp,nvar,nvar))))'\n",
    "    tmp   = reshape(COEFS[i,:]',nvar*lags+1,nvar)'\n",
    "    DYN   = tmp[:,1:nvar*lags]\n",
    "    MX    = [DYN;eye(nvar*(lags-1)) zeros(nvar*(lags-1),nvar)]\n",
    "    ME    = [S;zeros(nvar*(lags-1),nvar)]\n",
    "    modvar= state_space_model(MX,MY,ME,eye(nvar))\n",
    "    # 2) Compute IRFs and cumulative squared IRFs from Choleski decomposition\n",
    "    Itmp1 = zeros(nrep*ny,nvar)    # IRF\n",
    "    Itmp2 = zeros(ny,nvar)         # IRF at test horizon (to guarantee sign)\n",
    "    Itmp3 = zeros(maxhor*ny,nvar)  # cumulative squared IRF \n",
    "    for k in 1:nvar\n",
    "        tmp        = comp_irf(modvar,k,maxhor)\n",
    "        ttmp       = tmp.y[1:nrep,:]\n",
    "        Itmp1[:,k] = ttmp[:]\n",
    "        Itmp2[:,k] = tmp.y[test,:]'\n",
    "        vtmp       = tmp.y[1:maxhor,:]\n",
    "        Itmp3[:,k] = vtmp[:]\n",
    "    end\n",
    "    # 3) Computes the MBC shock, then the IRFs, FEV and variance decomposition to this shock.\n",
    "    QQ=zeros(nvar,ncase)    \n",
    "    for ic in 1:ncase\n",
    "        idx             = Idv[ic]\n",
    "        nidx            = length(idx)\n",
    "        weight          = ones(1,nidx)/nidx  # weight to assign to each variable when trying to maximize other several variables.        \n",
    "        Q               = funcfdq(modvar,S,wmin,wmax,idx,weight)\n",
    "        sgn             = sign((Itmp2[idx[1],:]'*Q)[1])\n",
    "        Qmat[ic,i,:]    = sgn*Q\n",
    "        IRFsr[ic,i,:]   = sgn*(Itmp1*Q)\n",
    "        y1,y2           = share_trans(modvar,S,Q)\n",
    "        SVTsr[ic,i,:]   = y1\n",
    "        SVTlr[ic,i,:]   = y2\n",
    "        VDtmp           = vdec(Itmp3,Q,maxhor)\n",
    "        VD[ic,i,:]      = VDtmp[:]\n",
    "    end\n",
    "end\n",
    "# Generate IRF, FEV and Variance decomposition average, median and confidence bands\n",
    "airf   = zeros(ncase,nrep,ny)\n",
    "mirf   = zeros(ncase,nrep,ny)\n",
    "lirf   = zeros(ncase,nrep,ny)\n",
    "sirf   = zeros(ncase,nrep,ny)\n",
    "afev   = zeros(ncase,maxhor,ny)\n",
    "mfev   = zeros(ncase,maxhor,ny)\n",
    "lfev   = zeros(ncase,maxhor,ny)\n",
    "sfev   = zeros(ncase,maxhor,ny)\n",
    "asvtsr = zeros(ncase,ny)\n",
    "msvtsr = zeros(ncase,ny)\n",
    "lsvtsr = zeros(ncase,ny)\n",
    "ssvtsr = zeros(ncase,ny)\n",
    "asvtlr = zeros(ncase,ny)\n",
    "msvtlr = zeros(ncase,ny)\n",
    "lsvtlr = zeros(ncase,ny)\n",
    "ssvtlr = zeros(ncase,ny)\n",
    "for ic in 1:ncase\n",
    "    airf[ic,:,:] = reshape(mean(IRFsr[ic,:,:],dims=1),nrep,ny)\n",
    "    mirf[ic,:,:] = reshape(median(IRFsr[ic,:,:],dims=1),nrep,ny)\n",
    "    pcl          = [percentile(IRFsr[ic,:,i],(100-alpha)/2) for i=1:nrep*ny]\n",
    "    pcs          = [percentile(IRFsr[ic,:,i],100-(100-alpha)/2) for i=1:nrep*ny]\n",
    "    lirf[ic,:,:] = reshape(pcl,nrep,ny)\n",
    "    sirf[ic,:,:] = reshape(pcs,nrep,ny)\n",
    "\n",
    "    afev[ic,:,:] = reshape(mean(VD[ic,:,:],dims=1),maxhor,ny)\n",
    "    mfev[ic,:,:] = reshape(median(VD[ic,:,:],dims=1),maxhor,ny)\n",
    "    pcl          = [percentile(VD[ic,:,i],(100-alpha)/2) for i=1:maxhor*ny]\n",
    "    pcs          = [percentile(VD[ic,:,i],100-(100-alpha)/2) for i=1:maxhor*ny]\n",
    "    lfev[ic,:,:] = reshape(pcl,maxhor,ny)\n",
    "    sfev[ic,:,:] = reshape(pcs,maxhor,ny)\n",
    "    \n",
    "    \n",
    "    asvtsr[ic,:] = mean(SVTsr[ic,:,:],dims=1)\n",
    "    msvtsr[ic,:] = median(SVTsr[ic,:,:],dims=1)\n",
    "    lsvtsr[ic,:] = [percentile(SVTsr[ic,:,i],(100-alpha)/2) for i=1:ny]\n",
    "    ssvtsr[ic,:] = [percentile(SVTsr[ic,:,i],100-(100-alpha)/2) for i=1:ny]\n",
    "\n",
    "    asvtlr[ic,:] = mean(SVTlr[ic,:,:],dims=1)\n",
    "    msvtlr[ic,:] = median(SVTlr[ic,:,:],dims=1)\n",
    "    lsvtlr[ic,:] = [percentile(SVTlr[ic,:,i],(100-alpha)/2) for i=1:ny]\n",
    "    ssvtlr[ic,:] = [percentile(SVTlr[ic,:,i],100-(100-alpha)/2) for i=1:ny]\n",
    "end\n",
    "\n",
    "\n",
    "if save_\n",
    "    fres = matopen(fileres, \"w\")\n",
    "    write(fres,\"airf\",airf)\n",
    "    write(fres,\"mirf\",mirf)\n",
    "    write(fres,\"lirf\",lirf)\n",
    "    write(fres,\"sirf\",sirf)\n",
    "    write(fres,\"afev\",afev)\n",
    "    write(fres,\"mfev\",mfev)\n",
    "    write(fres,\"lfev\",lfev)\n",
    "    write(fres,\"sfev\",sfev)\n",
    "    write(fres,\"asvtsr\",asvtsr)\n",
    "    write(fres,\"msvtsr\",msvtsr)\n",
    "    write(fres,\"lsvtsr\",lsvtsr)\n",
    "    write(fres,\"ssvtsr\",ssvtsr)\n",
    "    write(fres,\"asvtlr\",asvtlr)\n",
    "    write(fres,\"msvtlr\",msvtlr)\n",
    "    write(fres,\"lsvtlr\",lsvtlr)\n",
    "    write(fres,\"ssvtlr\",ssvtlr)\n",
    "    write(fres,\"Qmat\",Qmat)\n",
    "    write(fres,\"VOL\",VOL)\n",
    "    write(fres,\"COEFS\",COEFS)\n",
    "    close(fres)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "julia-0.5"
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
